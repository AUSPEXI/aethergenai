<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Context Engineering: From RAG to Reliable Answers</title>
  <meta name="description" content="Hybrid retrieval, context quality signals, and budget packing that feed Risk Guard and evidence provenance." />
  <style>body{font-family:Inter,system-ui,Arial,sans-serif;line-height:1.65;color:#0f172a;margin:0;background:#f5f7fb}.article{max-width:960px;margin:0 auto;background:#fff;padding:48px 36px;box-shadow:0 10px 30px rgba(0,0,0,.06);border-radius:12px}h1{font-size:36px;margin:0 0 8px;color:#0b1220}.meta{color:#475569;font-size:14px;margin-bottom:28px}h2{color:#0b1220;margin-top:36px;font-size:26px}ul{padding-left:20px}.callout{background:#ecfeff;border-left:4px solid #06b6d4;padding:16px;border-radius:8px}</style>
</head>
<body>
<div class="article">
  <h1>Context Engineering: From RAG to Reliable Answers</h1>
  <div class="meta"><strong>Auspexi</strong> • Updated: <script>document.write(new Date().toISOString().slice(0,10))</script></div>
  <div class="callout"><strong>TL;DR</strong>: We add a context layer on top of RAG: hybrid retrieval (BM25+dense+reranker), context signals (retrieval_margin, support_docs, recency, trust, format), token budget packing, and evidence provenance. Signals feed the Risk Guard to fetch/clarify/abstain before generation.</div>
  <h2>Why context wins (a short story)</h2>
  <p>Two identical models answer the same question. One sees a clean, relevant brief with citations; the other sees a noisy dump. The first answers correctly and concisely; the second hallucinates. Same model, different context. Our job is to engineer the brief.</p>

  <h2>Hybrid Retrieval</h2>
  <ul>
    <li>Combine BM25 + dense embeddings and an optional cross‑encoder reranker</li>
    <li>MMR‑style de‑duplication; boosts for recency and source trust</li>
  </ul>
  <h2>Signals and Policy</h2>
  <ul>
    <li>Signals: retrieval_margin, support_docs, recency_score, source_trust, format_health</li>
    <li>Policy: if signals are thin → fetch more, clarify, or abstain; otherwise generate</li>
  </ul>
  <p>Signals map into our pre‑generation Risk Guard. High margin + strong support lowers risk; low margin + weak support triggers fetch or abstain. This prevents wasted tokens and bad answers.</p>

  <h2>What good context looks like</h2>
  <ul>
    <li>Short and scoped: only spans that directly answer the question</li>
    <li>Citation‑ready: include source IDs and hashable excerpts</li>
    <li>Fresh enough: decay old content unless explicitly requested</li>
    <li>Typed tool outputs: strict JSON or tables; no blob dumps</li>
  </ul>

  <h2>Budget packing</h2>
  <p>We score spans, then pack them into a token budget so the model sees the best 2–3 pages of truth instead of 30 pages of noise. The remainder is accessible on demand.</p>

  <h2>Evidence</h2>
  <p>We ship context_provenance.json inside evidence zips with per‑query signals and included sources for audit.</p>

  <h2>Measuring improvement</h2>
  <ul>
    <li>Retrieval: P@k, nDCG@k, citation‑hit rate</li>
    <li>Answer quality: correctness@k, abstain rate at fixed coverage</li>
    <li>Ops: token cost per accepted answer, latency p95</li>
  </ul>
  <h2>Get Started</h2>
  <ul>
    <li><a href="/context-engineering">Context Engineering page</a></li>
    <li><a href="/whitepaper#context">Whitepaper section</a></li>
  </ul>
</div>
</body>
</html>


