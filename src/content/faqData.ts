export type FAQItem = { q: string; a: string }
export type FAQSection = { id: string; title: string; items: FAQItem[] }

// High-level, public-safe FAQs. No proprietary implementation details.
export const faqSections: FAQSection[] = [
  {
    id: 'platform',
    title: 'Platform & Packaging',
    items: [
      { q: 'What is AethergenPlatform in one sentence?', a: 'A governed synthetic-data and model delivery platform that pairs generation tools with signed evidence and enterprise delivery (Unity Catalog).' },
      { q: 'How is Platform different from Enterprise?', a: 'Platform provides self-serve tools and quotas; Enterprise is managed delivery on your Databricks with SLAs, evidence, and change control.' },
      { q: 'What artifacts can I export from the Platform?', a: 'Synthetic datasets, evidence bundles (JSON + signed zip), dataset/model cards, packaging manifests, and UC-ready assets.' },
      { q: 'Does the Platform include models?', a: 'Yes—domain packs and model seats exist, but production delivery is governed by evidence and acceptance gates.' },
      { q: 'How portable are assets?', a: 'Schemas, evidence, and packages are designed to be cloud-agnostic and reproducible, with Databricks UC as the primary enterprise target.' },
      { q: 'Can I bring my own pipelines?', a: 'Yes. Platform functions as a toolbox; you can integrate your preprocessing, training, or evaluation where interfaces match.' },
      { q: 'Do you support dataset versioning?', a: 'Yes—dataset versions and evidence bundles can be tracked, hashed, and referenced in UC comments or catalogs.' },
      { q: 'How do you avoid vendor lock-in?', a: 'We rely on standard formats (Parquet/Delta), public APIs, and signed evidence so assets stay verifiable outside our runtime.' },
      { q: 'What visibility do I have during generation?', a: 'Streaming progress, quotas, and guardrails are surfaced in UI; acceptance gates summarize privacy/utility upon completion.' },
      { q: 'Can I white-label the Platform?', a: 'Yes—white-label options exist with capped entitlements; Enterprise full-service licensing is also available.' },
    ],
  },
  {
    id: 'hallucinations',
    title: 'Hallucination Controls & Reliability',
    items: [
      { q: 'Do you try to “eliminate” hallucinations?', a: 'We reduce their impact at decision time. We optimize a 3‑state objective (correct, abstain, wrong) and reward calibrated abstention over confident error.' },
      { q: 'How do you decide when to abstain?', a: 'A lightweight information‑sufficiency gate scores support; low support routes to retrieval/tools, clarification, or abstain.' },
      { q: 'What verification do you perform?', a: 'Schema/units/range checks, citation/consistency tests, and simple cross‑checks. If verification fails, the system fails‑closed.' },
      { q: 'How are operating points chosen?', a: 'We trade coverage for precision by risk class and latency budget. Coverage–precision curves are reported in evidence.' },
      { q: 'How do you measure lift credibly?', a: 'Clamp latency and coverage, then compare wrong‑answer rate and re‑ask rate on a fresh‑news holdout pre/post gating.' },
      { q: 'What happens when support is thin?', a: 'We use retrieval, tools, or ask for clarification. If still insufficient, we abstain with a clear reason.' },
      { q: 'Do controls over‑abstain?', a: 'Controls are tuned per domain. Shadow tests and SLOs track abstain rates; thresholds are adjusted to maintain useful coverage.' },
      { q: 'How do you handle domain shift?', a: 'Stability and drift monitors surface shifts; operating points and retrieval sources can be adapted, and changes documented in evidence.' },
      { q: 'Are results auditable?', a: 'Yes—decisions and acceptance results are logged in signed evidence bundles for reproduction by auditors.' },
      { q: 'Can we disable controls?', a: 'Enterprise can configure thresholds, but safety gates default to fail‑closed for high‑risk workflows.' },
      { q: 'What is the Risk Guard?', a: 'A pre‑generation risk score that estimates hallucination likelihood before answering, enabling actions like fetch‑more‑context, abstain, or reroute.' },
      { q: 'How is risk computed?', a: 'From signals like margin, entropy, retrieval support, and optional self‑consistency. We calibrate a threshold to bound hallucination rate (e.g., 5%).' },
      { q: 'How do thresholds work?', a: 'Pick a target hallucination rate (e.g., 0.05). Calibrate a risk threshold so that responses below the threshold satisfy the target on held‑out data.' },
      { q: 'What actions are taken at high risk?', a: 'If risk exceeds the threshold, we fetch more context, abstain (fail‑closed), or reroute to a different backend/policy.' },
      { q: 'Is this audited?', a: 'Risk thresholds and outcomes can be logged in evidence bundles alongside selective prediction and SLOs for auditability.' },
    ],
  },
  {
    id: 'data-calibration',
    title: 'Data & Calibration (Anchors, Seeds)',
    items: [
      { q: 'What is an anchor bundle?', a: 'A JSON of aggregates (counts, quantiles, correlations, tails, segment mixes) that calibrates synthetic generation without sharing raw rows.' },
      { q: 'How do I create anchors?', a: 'Run our notebooks/SQL in your environment (e.g., Databricks/Snowflake/BigQuery) to compute DP-friendly summaries and export JSON.' },
      { q: 'Do I need both anchors and seeds?', a: 'No. Either is acceptable; both is best. Anchors calibrate distributions; ZKP seeds validate structure and rare cases without exposing rows.' },
      { q: 'What happens if anchors are noisy?', a: 'Quality gates may fail or widen uncertainty. You can refine anchors (better binning/segments) or add ZKP seeds for structure.' },
      { q: 'How do segments work?', a: 'Provide per-segment anchors (e.g., region, product). Stability and drift are checked per segment in evidence.' },
      { q: 'How are correlations captured?', a: 'Anchors can include pairwise correlations or copula-friendly summaries; we do not require raw joints.' },
      { q: 'Can anchors include time components?', a: 'Yes—quantiles or summaries per window let us respect temporal distributions and seasonality.' },
      { q: 'What schema alignment is required?', a: 'Field names, types, and units should match your governed schema; anchors reference those canonical fields.' },
      { q: 'Can anchors be differentially private?', a: 'Yes—support for DP budgets (ε, δ) and clipping/bucketing is built into the anchor workflow.' },
      { q: 'How are anchors referenced in evidence?', a: 'A stable anchor_hash is recorded in provenance (provenance/anchors.json) inside the signed evidence zip.' },
    ],
  },
  {
    id: 'privacy-safety',
    title: 'Privacy & Safety',
    items: [
      { q: 'What privacy probes are run?', a: 'Membership inference, attribute disclosure, and linkage-style checks, plus optional DP accounting where configured.' },
      { q: 'Do you use differential privacy?', a: 'Yes—optional. You can set ε/δ budgets; evidence documents posture and configuration.' },
      { q: 'How is PII handled?', a: 'We encourage anchors/ZKP flows instead of rows. If raw data is ever processed in your environment, PII policies and redaction are enforced at source.' },
      { q: 'What is the Policy Guard?', a: 'A runtime policy layer enforcing entitlements, geo/sector denies, and safety thresholds; violations revoke access automatically.' },
      { q: 'How does the kill switch operate?', a: 'On policy breach or incident, access to affected assets is revoked and artifacts quarantined pending review.' },
      { q: 'Can we audit privacy configurations?', a: 'Yes—privacy posture and probe results are embedded in the evidence bundle, signed and reproducible.' },
      { q: 'Do you store customer data?', a: 'No—anchors and ZKP flows avoid raw data transfer. If your topology requires processing, it stays in your environment.' },
      { q: 'How are failure modes communicated?', a: 'Evidence notes limits, failure modes, and intended use; acceptance gates fail-closed when thresholds are not met.' },
      { q: 'Are there sector-specific controls?', a: 'Yes—sector and geography rules can be configured to block certain asset usages.' },
      { q: 'How do you prevent overfitting to anchors?', a: 'Acceptance gates include holdout utility, stability by segment, and drift checks to detect overfit behaviors.' },
    ],
  },
  {
    id: 'ondevice',
    title: 'On‑Device AI & SLOs',
    items: [
      { q: 'What on‑device modes are supported?', a: 'Device‑only, hybrid (device first, cloud fallback), and cloud‑only. Hybrid is default for best latency and cost.' },
      { q: 'How is fallback rate controlled?', a: 'Set a max fallback rate SLO (e.g., 15%). Routing enforces it by tightening selective thresholds or deferring non‑urgent requests when the budget is at risk.' },
      { q: 'What about battery and thermal limits?', a: 'Set max battery mWh per inference and max temperature delta in °C. When limits are approached, the system reduces coverage, downshifts models, or routes to cloud.' },
      { q: 'What telemetry is collected from devices?', a: 'Sampled local metrics: p95 latency, energy estimate, temperature delta, fallback reasons. Raw data stays on device; optional DP summaries may sync.' },
      { q: 'How does this interact with selective prediction?', a: 'Selective thresholds can be tuned per device class to meet target coverage while respecting battery/thermal budgets and fallback caps.' },
      { q: 'Do NPUs change behavior?', a: 'We detect supported ops and prefer NPU; fallback chain is NPU → GPU → CPU. Unsupported ops raise telemetry to inform builds.' },
      { q: 'Where is the playbook?', a: 'See Resources → On‑Device AI Playbook for routing, SLOs, packaging, and telemetry guidance.' },
    ],
  },
  {
    id: 'delivery-uc',
    title: 'Delivery (Unity Catalog)',
    items: [
      { q: 'What UC objects do you create?', a: 'Catalog, Schema, Volumes (managed) for datasets; comments/tags can reference evidence and anchor hashes.' },
      { q: 'Who owns the UC assets?', a: 'You do. We operate under least privilege and change control during managed delivery.' },
      { q: 'How are permissions handled?', a: 'We apply grants to roles/groups per your policy; changes are logged and reproducible.' },
      { q: 'Do you support Marketplace?', a: 'Yes—packaging for listings and private offers, referencing UC assets and evidence bundles.' },
      { q: 'How do you handle environments?', a: 'Dev/Stage/Prod catalogs with explicit promotion rules and evidence snapshots to ensure traceability.' },
      { q: 'Can models be registered?', a: 'Yes—model registration and comments with evidence references are supported per your UC governance.' },
      { q: 'How are updates rolled out?', a: 'Change windows and approvals; previous versions remain addressable; rollback plans are included in runbooks.' },
      { q: 'Do you tag assets?', a: 'Yes—domain, license, sensitivity, and lineage tags can be applied to aid catalog governance and search.' },
      { q: 'How do you surface evidence links?', a: 'UC comments/tags include manifest and anchor_hash references for auditors and buyers.' },
      { q: 'What happens on schema evolution?', a: 'Versioned schemas and migration guidance are included in documentation to keep lineage intact.' },
    ],
  },
  {
    id: 'evidence',
    title: 'Evidence & Governance',
    items: [
      { q: 'What is an evidence bundle?', a: 'A signed, reproducible package (JSON + zip) with provenance, privacy probes, utility metrics, ablations, manifests, and checksums.' },
      { q: 'How is evidence verified?', a: 'Signatures and hashes allow independent verification; auditors confirm integrity and acceptance criteria.' },
      { q: 'What KPIs are included?', a: 'Utility (e.g., AUC/F1/MAE), KS/TV distribution alignment, stability by segment, drift snapshots, and latency where applicable.' },
      { q: 'Can evidence be redacted for sharing?', a: 'Yes—public redacted variants can be generated to share non-sensitive summaries.' },
      { q: 'Is evidence versioned?', a: 'Yes—bundle versions and manifest IDs are immutable; UC comments can pin exact evidence releases.' },
      { q: 'How do you encode provenance?', a: 'Seed and anchor references (hashes), schema versions, recipe IDs, and artifact checksums are included for traceability.' },
      { q: 'Do you include acceptance gates?', a: 'Yes—evidence states pass/fail and the thresholds used; fail-closed is the default.' },
      { q: 'Can buyers keep evidence with contracts?', a: 'Yes—evidence zips are deliverables designed for procurement archives.' },
      { q: 'Are ablations included?', a: 'Yes—module toggles and budget sensitivity analyses are summarized to show causal impacts.' },
      { q: 'How does evidence tie to Marketplace?', a: 'Listings reference evidence so buyers can assess quality and governance before enabling access.' },
    ],
  },
  {
    id: 'streams-edge',
    title: 'Streams & Edge',
    items: [
      { q: 'What is a stream?', a: 'Continuous generation with SLAs, suited to near-real-time workflows; governed like datasets but delivered as feeds.' },
      { q: 'How do edge packages work?', a: 'Signed, offline bundles with manifests, QR verification, SOPs, and evidence excerpts for air-gapped or constrained sites.' },
      { q: 'How is device variability handled?', a: 'Profiles and fallbacks define safe operating envelopes; evidence can include device-aware evaluation results.' },
      { q: 'Can streams write Delta?', a: 'Yes—streams can target managed locations; compaction/optimization settings are environment-specific.' },
      { q: 'What happens on disconnect?', a: 'Edge bundles are designed for offline verification and re-sync once connectivity returns.' },
      { q: 'Are rate limits enforced?', a: 'Yes—quotas and backpressure protect stability; violations trigger policy actions.' },
      { q: 'How are updates applied at the edge?', a: 'Signed updates with version pinning and rollback SOPs; changes require approval in managed contexts.' },
      { q: 'Do you include latency reporting?', a: 'Yes—optional latency/throughput summaries appear in evidence for streams and edge rollouts.' },
      { q: 'Can streams be paused?', a: 'Yes—policy and ops controls allow pause/resume with clear states.' },
      { q: 'How do you verify edge integrity?', a: 'Manifests, signatures, and QR checks enable offline verification before activation.' },
    ],
  },
  {
    id: 'context-training',
    title: 'Context & Training',
    items: [
      { q: 'How does context ingestion work?', a: 'Context is ingested with governance and filters; only approved sources feed training/evaluation, and provenance is recorded.' },
      { q: 'Do you support ablation testing?', a: 'Yes—recipes support controlled toggles; differences are captured in evidence for causality and safety.' },
      { q: 'How are operating points selected?', a: 'You can specify target false-positive budgets or other constraints; evidence reports metrics at selected operating points.' },
      { q: 'Can we plug in our own trainers?', a: 'Yes—so long as outputs conform to reporting interfaces, custom training is supported.' },
      { q: 'How do you ensure reproducibility?', a: 'Seeded runs, pinned versions, and signed manifests provide repeatable outcomes across environments.' },
      { q: 'Is fine-tuning supported?', a: 'Yes—policy-permitting, adapters or custom layers can be trained and evaluated under governance.' },
      { q: 'How do you prevent data leakage?', a: 'Separation of calibration vs evaluation, strict lineage tracking, and privacy probes reduce leakage risk.' },
      { q: 'Do you measure robustness?', a: 'Yes—optional robustness suites report sensitivity to corruptions/perturbations with simple summaries in evidence.' },
      { q: 'Can I run quick checks before full jobs?', a: 'Yes—lightweight smoke tests verify schema/anchors and budget configs to catch issues early.' },
      { q: 'How are failures surfaced?', a: 'UI status, logs, and evidence fail states highlight which gates failed and recommended actions.' },
    ],
  },
  {
    id: 'carbon',
    title: 'Carbon & Sustainability',
    items: [
      { q: 'Do you track carbon metrics?', a: 'Yes—training/inference footprints can be estimated; optional summaries can be embedded in evidence for transparency.' },
      { q: 'Is energy data device-aware?', a: 'Where available, device profiles inform estimation; otherwise standardized assumptions are used.' },
      { q: 'Do you offer optimization guidance?', a: 'Yes—evidence can include efficiency deltas (quantization/pruning/early-stopping) to inform greener operation.' },
      { q: 'Can buyers request ESG appendices?', a: 'Yes—optional ESG summaries are attachable for procurement and reporting.' },
      { q: 'How do you avoid greenwashing?', a: 'We report method and assumptions explicitly and keep figures within verifiable bounds.' },
      { q: 'Is there support for carbon budgets?', a: 'Policies can encode guardrails or alerts for energy/carbon exceedances in managed contexts.' },
      { q: 'Do you track water usage?', a: 'Basic placeholders exist; expanded environmental metrics can be added on request.' },
      { q: 'Can carbon be tied to SLAs?', a: 'Yes—Enterprise contracts may include reporting cadences and targets for transparency.' },
      { q: 'Do you compare configurations?', a: 'Yes—efficiency reports can compare baseline vs optimized configurations at similar quality.' },
      { q: 'How is data validated?', a: 'Methodology notes are included in evidence; where precise metering is not available, we label estimates clearly.' },
    ],
  },
  {
    id: 'security',
    title: 'Security, Policy, Kill Switch',
    items: [
      { q: 'How are entitlements enforced?', a: 'API keys, roles, and policy checks gate functionality. Enterprise integrates with your identity and groups.' },
      { q: 'Do you support geo/sector denies?', a: 'Yes—configurable lists block use in disallowed jurisdictions or sectors.' },
      { q: 'What triggers the kill switch?', a: 'Breaches of policy, incident signals, or safety gate failures can trigger automated revocation.' },
      { q: 'How do you handle incidents?', a: 'Runbooks define snapshot, classification, mitigation, root cause, and actions; evidence and logs aid postmortems.' },
      { q: 'Is data encrypted?', a: 'All transit encryption is mandatory; at-rest encryption follows the hosting cloud’s KMS policies in Enterprise deployments.' },
      { q: 'Can we audit actions?', a: 'Yes—management actions and deliveries are logged; evidence captures critical workflow states.' },
      { q: 'How are secrets managed?', a: 'Enterprise uses your cloud’s secret stores; Platform avoids storing customer secrets where possible.' },
      { q: 'What about rate limiting/abuse?', a: 'Platform quotas and rate limits protect shared resources and reduce risk.' },
      { q: 'Is there a revocation list?', a: 'Evidence bundles and keys can include revocation metadata for lifecycle management.' },
      { q: 'How do you validate packages?', a: 'Signatures and hashes are verified before activation; mismatches are rejected.' },
    ],
  },
  {
    id: 'support',
    title: 'Support & SLAs',
    items: [
      { q: 'What support comes with Platform?', a: 'Community/standard support, documentation, and sample notebooks; optional paid support available.' },
      { q: 'What’s included in Enterprise support?', a: 'Named contacts, SLAs, change control, scheduled maintenance windows, and evidence per release.' },
      { q: 'How are issues prioritized?', a: 'Severity-based triage with agreed response/resolution targets for Enterprise.' },
      { q: 'Do you provide onboarding?', a: 'Yes—guided setup for UC, anchors/ZKP workflows, and evidence pipelines.' },
      { q: 'Are training sessions available?', a: 'Workshops and knowledge transfer sessions can be added to Enterprise engagements.' },
      { q: 'Can we get architectural reviews?', a: 'Yes—reviews ensure schemas, anchors, and delivery match governance expectations.' },
      { q: 'How do upgrades work?', a: 'Versioned releases with compatibility notes; Enterprise receives change notices and windows.' },
      { q: 'Do you support trials?', a: 'Time-limited evaluations with illustrative packs are possible before calibration.' },
      { q: 'Is there 24/7 support?', a: 'Optional for Enterprise; otherwise business hours with on-call escalation for critical incidents.' },
      { q: 'Where is documentation?', a: 'Docs, blog posts, and UI help links; Enterprise receives runbooks and SOPs.' },
    ],
  },
  {
    id: 'pricing',
    title: 'Pricing & Entitlements',
    items: [
      { q: 'Do Platform plans include datasets?', a: 'Platform focuses on tools; datasets are separate SKUs so you only buy what you need.' },
      { q: 'What is included in Enterprise pricing?', a: 'Managed compute, UC delivery, evidence bundles, SLAs, and support—defined by contract.' },
      { q: 'How are quotas enforced?', a: 'Rows/month, ablations, and API RPS caps; Enterprise removes or negotiates caps under SLAs.' },
      { q: 'Can I switch tiers later?', a: 'Yes—upgrade paths and migration of recipes/evidence are supported.' },
      { q: 'Do you meter predictions?', a: 'Yes—model rental and prediction credits are usage-based with clear rates.' },
      { q: 'Are there overage fees?', a: 'Overages are either throttled or billed as per contract; Platform defaults to throttling.' },
      { q: 'Is white-label usage unlimited?', a: 'No—white-label has capped entitlements; for unlimited, use Enterprise Platform licensing.' },
      { q: 'How are add-ons billed?', a: 'Calibration services, Anchor Assist, and Marketplace packaging are separately priced line items.' },
      { q: 'Do you offer discounts?', a: 'Volume and term discounts are available for Enterprise contracts.' },
      { q: 'How are taxes handled?', a: 'Pricing is exclusive of taxes; final invoices include applicable tax based on jurisdiction.' },
    ],
  },
  {
    id: 'roadmap',
    title: 'Roadmap & Innovation',
    items: [
      { q: 'What have you achieved so far?', a: 'Billion-scale synthetic generation demo, UC enterprise delivery with evidence, and calibrated workflows using anchors/ZKP.' },
      { q: 'What is near-term focus?', a: 'Improving anchor tooling, expanding evidence automation, and Marketplace packaging.' },
      { q: 'How do you balance disclosure and IP?', a: 'We publish reproducible, verifiable outcomes (evidence) while withholding implementation details that are proprietary.' },
      { q: 'Do you share benchmarks?', a: 'We publish task metrics and acceptance thresholds in evidence; comparative claims are kept within auditable bounds.' },
      { q: 'How do you prioritize features?', a: 'Buyer feedback, regulatory needs, and governance impact guide priorities.' },
      { q: 'Will you add more clouds?', a: 'We already operate across clouds; UC/Delta is primary for enterprise, with portability for others.' },
      { q: 'Do you support on-prem?', a: 'Case-by-case for Enterprise; governance and evidence requirements still apply.' },
      { q: 'Are there public APIs?', a: 'Yes—core operations are API-driven; rate limits and quotas apply to Platform.' },
      { q: 'Can partners list on Marketplace?', a: 'Yes—curated partner model/dataset listings with unified evidence flows are in scope.' },
      { q: 'How do you mitigate model collapse/drift?', a: 'Stability monitors, drift checks, and evidence fail-closed gates reduce collapse risks; anchors help prevent distribution drift.' },
    ],
  },
]


